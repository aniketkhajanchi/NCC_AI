<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE html
  PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" xml:lang="en" lang="en">
<head><meta http-equiv="Content-Type" content="text/html; charset=UTF-8" />

<meta name="copyright" content="(C) Copyright 2023" />
<meta name="DC.rights.owner" content="(C) Copyright 2023" />
<meta name="generator" content="DITA-OT" /><meta name="DC.type" content="concept" />
<meta name="DC.title" content="Disaster recovery for geographically redundant RMS deployments" />
<meta name="prodname" content="Nokia Converged Charging" />
<meta name="version" content="Release 23.8" />
<meta name="DC.format" content="XHTML" />
<meta name="DC.identifier" content="disaster_recovery_for_geo_rms" />
<link rel="stylesheet" type="text/css" href="../../web/css/commonltr.css" />
<link rel="stylesheet" type="text/css" href="../../web/css/styles.min.css" />
<link rel="stylesheet" type="text/css" href="../../web/css/common-extended.css" /><title>Disaster recovery for geographically redundant RMS deployments</title>
<script src="../web/js/nswtc.js" language="javascript" type="text/javascript">/*(◎_◎;)*/</script>
<script src="../../web/css/../js/script.min.js" language="javascript" type="text/javascript">/*(◎_◎;)*/</script>
</head>
<body id="disaster_recovery_for_geo_rms">
<div class="header"><div id="feedback-link-placeholder" class="feedback-link"></div><hr /></div><h1 class="title topictitle1" id="ariaid-title1">Disaster recovery for geographically redundant RMS deployments </h1>
<div class="body conbody">
        <p class="p">In network deployments with multiple RMS systems, when data replication failures between
            systems and the binary logs on the primary system are too outdated to allow successful
            replication, the systems must be brought back in sync. The standard <span class="ph">NCC</span> backup and
            restore solution is not appropriate since only the database directory is copied and not
            the SQL statements that may affect replication.</p>

        <p class="p">When this happens, the secondary system must be restored from primary system. Ensure that
            the issues which failed the data replication are resolved before performing this
            activity.</p>

        <p class="p">Data backup or restore can be accomplished by using the
                <code class="ph codeph">mariadb_db_backup</code> script which is built into the
                <span class="ph filepath">cmdb/mariadb</span> container image. This
                <code class="ph codeph">mariadb_db_backup</code> script is based on the standard MariaDB
            mariabackup utility that is included in the distribution. This procedure assumes that
                <code class="ph codeph">rms1</code> is the primary working system and <code class="ph codeph">rms2</code> is the
            system that must be restored from <code class="ph codeph">rms1</code>.</p>

        <div class="section" id="disaster_recovery_for_geo_rms__section_rsx_wb5_h5b"><h2 class="title sectiontitle">Backup or Restore Procedure</h2>
            
        </div>

        <div class="section" id="disaster_recovery_for_geo_rms__section_imb_t15_h5b"><h2 class="title sectiontitle">Backup or Restore Procedure without re-installing rms2</h2>
            
            <ol class="ol" id="disaster_recovery_for_geo_rms__ol_fzd_5gy_xtb">
                <li class="li">
                    <p class="p">To backup from the <code class="ph codeph">rms1</code> primary node:</p>

                    <p class="p">- Determine which node to be used from primary system for backup. </p>

                    <p class="p">- It is safe to choose a secondary node to take the backup from, hence the
                        backup shall not interfere with primary operation. </p>

                    <p class="p">You can also take the backup from the primary if you desire, but it is
                        advisable to backup from the current secondary. To determine the correct
                        secondary node in the primary system to take the backup from, check the list
                        server status and the replication status. On the MaxScale node, run: </p>

                    <pre class="pre codeblock" id="disaster_recovery_for_geo_rms__codeblock_pcr_hb5_h5b"><code>/lib/mariadb/maxscale_rest_api.py --list-servers</code></pre>
                </li>

                <li class="li">Check replication status on <code class="ph codeph">rms1</code> primary:
                    <pre class="pre codeblock" id="disaster_recovery_for_geo_rms__codeblock_qcr_hb5_h5b"><code>/usr/bin/mariadb_adm --replication-status</code></pre></li>

                <li class="li">Check the Secondary GTID Position and Seconds Behind Master to find the farthest
                    secondary. Perform a full backup of the database on the farthest secondary
                    server by running this on the secondary node:
                    <pre class="pre codeblock" id="disaster_recovery_for_geo_rms__codeblock_gdz_3lq_g5b"><code>touch /mariadb/backup/incr/.clean </code></pre><pre class="pre codeblock" id="disaster_recovery_for_geo_rms__codeblock_jcp_g1w_g5b"><code>/usr/bin/mariadb_db_backup --backup --file /mariadb/rms1-backup.tgz</code></pre></li>

                <li class="li">On the secondary system <code class="ph codeph">rms2</code> (to be restored), disable MaxScale
                    on the MaxScale node(s) to stop it from performing recovery actions while
                    restore is taking place. The stop-slave argument stops replication on the
                    primary node so replications from rms1 is temporarily stopped:
                    <pre class="pre codeblock" id="disaster_recovery_for_geo_rms__codeblock_rcr_hb5_h5b"><code>/usr/bin/maxscale_adm --disable --stop-slave</code></pre><pre class="pre codeblock" id="disaster_recovery_for_geo_rms__codeblock_scr_hb5_h5b"><code>/usr/lib/maxscale/maxscale_lib.py --maxscale-service=stop</code></pre></li>

                <li class="li">Get the latest copy of <code class="ph codeph">rms1</code> backup (see step 3). All of these
                    steps should be performed in the same maintenance window. This is necessary to
                    ensure that the restore operation has the latest copy. If more time has elapsed
                    between steps 3 and 7, you may want to re-execute step 3.</li>

                <li class="li">Copy the <span class="ph filepath">rms1-backup.tgz</span> (created in step 3) to each
                        <code class="ph codeph">rms2</code> database nodes <span class="ph filepath">/mariadb/</span>
                    directory.</li>

                <li class="li">Perform the database restore operation on each database node of
                        <code class="ph codeph">rms2</code> using the backup taken from <code class="ph codeph">rms1</code>:
                        <pre class="pre codeblock" id="disaster_recovery_for_geo_rms__codeblock_tcr_hb5_h5b"><code>/usr/bin/mariadb_db_backup --restore --all --file /mariadb/rms1-backup.tgz [--preserve]</code></pre><div class="note" id="disaster_recovery_for_geo_rms__note_jh2_t3y_xtb"><div class="notetitle"><img src="../../web/css/../images/note.svg" title="note-icon" class="noteicon" />Note:</div> If using replication filters, use the
                            <code class="ph codeph">preserve</code> option to preserve specific
                    tables.</div>
</li>

                <li class="li">Enable MaxScale on the rms2 MaxScale node(s):
                    <pre class="pre codeblock" id="disaster_recovery_for_geo_rms__codeblock_vdl_1cq_g5b"><code>/usr/lib/maxscale/maxscale_lib.py --maxscale-service=start</code></pre><pre class="pre codeblock" id="disaster_recovery_for_geo_rms__codeblock_vqw_1cq_g5b"><code>/usr/bin/maxscale_adm --enable</code></pre></li>

                <li class="li">Make sure the cluster returns as expected after MaxScale is restarted:
                    <pre class="pre codeblock" id="disaster_recovery_for_geo_rms__codeblock_ucr_hb5_h5b"><code>/lib/mariadb/maxscale_rest_api.py --list-servers</code></pre></li>

                <li class="li">If needed, repeat the above for other data centers in the cluster.</li>

                <li class="li">Check replication status with this command in MariaDB pod on both data centers
                    to make sure replication is running well.
                    <pre class="pre codeblock" id="disaster_recovery_for_geo_rms__codeblock_o4b_1lq_g5b"><code>bash-4.2$ mariadb_adm --replication-status</code></pre></li>

            </ol>

        </div>

        <div class="section" id="disaster_recovery_for_geo_rms__section_prx_c4y_xtb"><h2 class="title sectiontitle">Backup or restore procedure with re-installing rms2</h2>
            
            <div class="note" id="disaster_recovery_for_geo_rms__note_rps_l1w_g5b"><div class="notetitle"><img src="../../web/css/../images/note.svg" title="note-icon" class="noteicon" />Note:</div> This disaster recovery procedure covers only the
                    <code class="ph codeph">rms-cmdb</code> database data. If during re-installation of rms2, the
                    <code class="ph codeph">rms-server</code> is re-installed, then <code class="ph codeph">rms-server</code>
                and the <code class="ph codeph">rms-server</code> shared data directory should be taken a backup.
                At the end of the disaster recovery procedure, use this backup to restore rms-server
                shared data directory. The back up and restore procedure should follow section
                    <cite class="cite">RMS backup and restore</cite> in the <cite class="cite">Recharge User Guide</cite> for
                rms-server helm release.</div>

            <ol class="ol" id="disaster_recovery_for_geo_rms__ol_bjn_f4y_xtb">
                <li class="li">
                    <p class="p">To backup from the rms1 primary node:</p>

                    <p class="p">- Determine which node to be used from the primary system for backup. </p>

                    <p class="p">- It is safe to choose a secondary node to take the backup from, hence the
                        backup shall not interfere with primary operation. </p>

                    <p class="p">You could also take the backup from the primary if you desire, but it is
                        advisable to backup from a current secondary. To determine the correct
                        secondary node in the primary system to take the backup from, check the list
                        server status and the replication status. On the MaxScale node, run: </p>

                    <pre class="pre codeblock" id="disaster_recovery_for_geo_rms__codeblock_okm_1lq_g5b"><code>/lib/mariadb/maxscale_rest_api.py --list-servers</code></pre>
                </li>

                <li class="li">Check replication status on <code class="ph codeph">rms1</code> primary:
                    <pre class="pre codeblock" id="disaster_recovery_for_geo_rms__codeblock_dcd_blq_g5b"><code>/usr/bin/mariadb_adm --replication-status</code></pre></li>

                <li class="li">Check the Secondary GTID Position and Seconds Behind Master to find the farthest
                    secondary. Perform a full backup of the database on the farthest secondary
                    server by running this command on the secondary node (from step 2): 
                    <pre class="pre codeblock" id="disaster_recovery_for_geo_rms__codeblock_nr4_blq_g5b"><code>touch /mariadb/backup/incr/.clean
/usr/bin/mariadb_db_backup --backup --file /mariadb/rms1-backup.tgz</code></pre></li>

                <li class="li">Disable replication on rms1:
                    <pre class="pre codeblock" id="disaster_recovery_for_geo_rms__codeblock_ar3_clq_g5b"><code>maxscale_adm --stop-slave</code></pre></li>

                <li class="li">On the secondary data center rms2, run the command to install RMS and make sure
                    RMS is ready.</li>

                <li class="li">On the secondary system <code class="ph codeph">rms2</code> (to be restored), after RMS is
                    ready, disable MaxScale on the MaxScale node(s) to keep it from performing
                    recovery actions while the restore is taking place. The stop-slave argument
                    stops replication on the Primary node so replication from rms1 is temporarily
                    stopped:
                    <pre class="pre codeblock" id="disaster_recovery_for_geo_rms__codeblock_tlc_flq_g5b"><code>/usr/bin/maxscale_adm --disable --stop-slave</code></pre><pre class="pre codeblock" id="disaster_recovery_for_geo_rms__codeblock_bpk_3b5_h5b"><code>/usr/lib/maxscale/maxscale_lib.py --maxscale-service=stop</code></pre></li>

                <li class="li">Get the latest copy of <code class="ph codeph">rms1</code> backup (see step 3). All these
                    steps should be performed in the same maintenance window. This is necessary to
                    ensure that the restore operation has the latest copy. If more time has elapsed
                    between steps 3 and 7, you may want to re-run step 3.</li>

                <li class="li">Copy the <span class="ph filepath">rms1-backup.tgz</span> (created in step 3) to each
                        <code class="ph codeph">rms2</code> database nodes <code class="ph codeph">/mariadb/ dir</code>.</li>

                <li class="li">Perform the database restore operation on each database node of
                        <code class="ph codeph">rms2</code> using the backup taken from
                        <code class="ph codeph">rms1</code>:<pre class="pre codeblock" id="disaster_recovery_for_geo_rms__codeblock_mlf_glq_g5b"><code>/usr/bin/mariadb_db_backup --restore --all --file /mariadb/rms1-backup.tgz [--preserve]</code></pre><div class="note" id="disaster_recovery_for_geo_rms__note_dys_qpy_xtb"><div class="notetitle"><img src="../../web/css/../images/note.svg" title="note-icon" class="noteicon" />Note:</div> If using replication filters, use the
                            <code class="ph codeph">preserve</code> option to preserve specific tables.
                    </div>
</li>

                <li class="li">Enable MaxScale on the rms2 MaxScale node(s):
                    <pre class="pre codeblock" id="disaster_recovery_for_geo_rms__codeblock_ppl_kcq_g5b"><code>/usr/lib/maxscale/maxscale_lib.py --maxscale-service=start</code></pre><pre class="pre codeblock" id="disaster_recovery_for_geo_rms__codeblock_q3k_lcq_g5b"><code>/usr/bin/maxscale_adm --enable</code></pre></li>

                <li class="li">Make sure the cluster comes back as expected after MaxScale is restarted:
                    <pre class="pre codeblock" id="disaster_recovery_for_geo_rms__codeblock_vjp_mcq_g5b"><code>/lib/mariadb/maxscale_rest_api.py --list-servers</code></pre></li>

                <li class="li">On rms1, enable replication <code class="ph codeph">maxscale_adm --start-slave</code></li>

                <li class="li">Check replication status with below command in the MariaDB pod on both systems
                    to make sure replication is running.
                    <pre class="pre codeblock" id="disaster_recovery_for_geo_rms__codeblock_elh_ncq_g5b"><code>bash-4.2$ mariadb_adm --replication-status</code></pre>
                </li>

                <li class="li">If necessary, repeat the steps for other systems in the network deployment.</li>

            </ol>

        </div>

    </div>
<div class="footer"><hr /><p>Operations, Administration, and Maintenance Guide • P556766-DN1000055092-R23.8 • 1 • <a href="../home.html">Cover</a> • ©2023 Nokia. Nokia Confidential Information • Use subject to agreed restrictions on disclosure and use.</p></div></body>
</html>